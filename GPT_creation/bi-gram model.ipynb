{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c379396e-208d-42e0-ba18-513b57160d7f",
   "metadata": {},
   "source": [
    "# Coding transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3aebae53-4dc9-4dff-b8b8-6dfd6256b181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:36.133911Z",
     "iopub.status.busy": "2025-03-29T08:53:36.133911Z",
     "iopub.status.idle": "2025-03-29T08:53:38.029228Z",
     "shell.execute_reply": "2025-03-29T08:53:38.029228Z",
     "shell.execute_reply.started": "2025-03-29T08:53:36.133911Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9510c88a-086c-4b0c-be06-3591f3dbd5ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:38.029228Z",
     "iopub.status.busy": "2025-03-29T08:53:38.029228Z",
     "iopub.status.idle": "2025-03-29T08:53:40.452537Z",
     "shell.execute_reply": "2025-03-29T08:53:40.452537Z",
     "shell.execute_reply.started": "2025-03-29T08:53:38.029228Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54883ed-d855-4cc3-a6a8-d17c0d50021a",
   "metadata": {},
   "source": [
    "## Data retrieval\n",
    "Retrieve training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41381d04-acb6-435e-83d0-312bee8baf9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.452537Z",
     "iopub.status.busy": "2025-03-29T08:53:40.452537Z",
     "iopub.status.idle": "2025-03-29T08:53:40.457893Z",
     "shell.execute_reply": "2025-03-29T08:53:40.457893Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.452537Z"
    }
   },
   "outputs": [],
   "source": [
    "# download the tiny shakespeare dataset\n",
    "\n",
    "filename = 'input.txt'\n",
    "file_dir = os.path.join(os.getcwd(), 'data')\n",
    "file_path = os.path.join(file_dir, filename)\n",
    "\n",
    "if not os.path.exists(file_dir):\n",
    "    os.mkdir(file_dir)\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(requests.get(data_url).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87897303-5452-49a1-96e0-5bf5516ee562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.458865Z",
     "iopub.status.busy": "2025-03-29T08:53:40.458865Z",
     "iopub.status.idle": "2025-03-29T08:53:40.464813Z",
     "shell.execute_reply": "2025-03-29T08:53:40.464813Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.458865Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(file_path, 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d86d1665-1ea7-4327-962c-b3c8650fd3a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.465822Z",
     "iopub.status.busy": "2025-03-29T08:53:40.465822Z",
     "iopub.status.idle": "2025-03-29T08:53:40.469535Z",
     "shell.execute_reply": "2025-03-29T08:53:40.468914Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.465822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length 1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print('Dataset length', len(text), end = '\\n')\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d22678-2451-4bef-af2c-939d29c332a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.470540Z",
     "iopub.status.busy": "2025-03-29T08:53:40.470540Z",
     "iopub.status.idle": "2025-03-29T08:53:40.481392Z",
     "shell.execute_reply": "2025-03-29T08:53:40.480883Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.470540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary size 65\n",
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "# Create a simple token space using python inner methods\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print('Dictionary size', vocab_size)\n",
    "print(''.join(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b3ca5-c2a2-4ee2-9fb2-fdd142e73820",
   "metadata": {},
   "source": [
    "## Tokenizer strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46918859-9615-48be-9684-7f561dbfb10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.482215Z",
     "iopub.status.busy": "2025-03-29T08:53:40.481392Z",
     "iopub.status.idle": "2025-03-29T08:53:40.484822Z",
     "shell.execute_reply": "2025-03-29T08:53:40.484822Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.481392Z"
    }
   },
   "outputs": [],
   "source": [
    "text2ind = {j: i for i, j in enumerate(chars)}\n",
    "ind2text = {i: j for i, j in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "050ab9dd-4758-4029-b09c-3f335552b744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.486153Z",
     "iopub.status.busy": "2025-03-29T08:53:40.485832Z",
     "iopub.status.idle": "2025-03-29T08:53:40.489405Z",
     "shell.execute_reply": "2025-03-29T08:53:40.489405Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.486153Z"
    }
   },
   "outputs": [],
   "source": [
    "encode = lambda x: [text2ind[char] for char in x]\n",
    "decode = lambda x: [ind2text[ind] for ind in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "293a9485-7c29-49bd-8579-0cfc0a60e153",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.490353Z",
     "iopub.status.busy": "2025-03-29T08:53:40.490353Z",
     "iopub.status.idle": "2025-03-29T08:53:40.493265Z",
     "shell.execute_reply": "2025-03-29T08:53:40.493265Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.490353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 47, 1, 58, 46, 43, 56, 43]\n",
      "['H', 'i', ' ', 't', 'h', 'e', 'r', 'e']\n"
     ]
    }
   ],
   "source": [
    "print(encode('Hi there'))\n",
    "print(decode(encode('Hi there')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5072a67-3d81-44d7-9aa7-8d433c816d38",
   "metadata": {},
   "source": [
    "Tokenizer uses simple encoding and decoding strategies that represent simple look-up tables that operate only at char level (because we're working with simple char-level transformer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a720a87-fa15-40df-b195-eb0c656c3610",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.494533Z",
     "iopub.status.busy": "2025-03-29T08:53:40.494533Z",
     "iopub.status.idle": "2025-03-29T08:53:40.575527Z",
     "shell.execute_reply": "2025-03-29T08:53:40.575527Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.494533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype = torch.long) # torch.long represents int64 \n",
    "print(data.shape, data.dtype) # -> Shape of a known dataset that was seen previously\n",
    "\n",
    "print(data[:50]) # -> Encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee3c1a28-9cd2-4960-ba83-97323a9d78cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.575527Z",
     "iopub.status.busy": "2025-03-29T08:53:40.575527Z",
     "iopub.status.idle": "2025-03-29T08:53:40.579277Z",
     "shell.execute_reply": "2025-03-29T08:53:40.578969Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.575527Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "\n",
    "n = int(0.9*len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "257213e5-218b-44ef-b4e1-c96b8957deca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.580204Z",
     "iopub.status.busy": "2025-03-29T08:53:40.579277Z",
     "iopub.status.idle": "2025-03-29T08:53:40.588741Z",
     "shell.execute_reply": "2025-03-29T08:53:40.588741Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.580204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['F', 'i', 'r', 's', 't', ' ', 'C', 'i', 't']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 # Context length\n",
    "print(train_data[:block_size+1])\n",
    "decode(train_data[:block_size+1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a90b68ee-03ec-408a-8239-da04dcbc1cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.588741Z",
     "iopub.status.busy": "2025-03-29T08:53:40.588741Z",
     "iopub.status.idle": "2025-03-29T08:53:40.592221Z",
     "shell.execute_reply": "2025-03-29T08:53:40.592221Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.588741Z"
    }
   },
   "outputs": [],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23de36e5-a7ab-4b59-8605-eb214a09ca1a",
   "metadata": {},
   "source": [
    "Training data consists of `x` and `y` lists, that are packed each with 8 symbols. For each item in `x` list item in `y` list is considered the following one in context of all preceding `x` items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4541d899-7fbf-4532-85e4-822b219ce511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.593267Z",
     "iopub.status.busy": "2025-03-29T08:53:40.593267Z",
     "iopub.status.idle": "2025-03-29T08:53:40.598687Z",
     "shell.execute_reply": "2025-03-29T08:53:40.597771Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.593267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([18]) corresponds to ouptut 47\n",
      "Input: ['F'] corresponds to ouptut ['i']\n",
      "Input: tensor([18, 47]) corresponds to ouptut 56\n",
      "Input: ['F', 'i'] corresponds to ouptut ['r']\n",
      "Input: tensor([18, 47, 56]) corresponds to ouptut 57\n",
      "Input: ['F', 'i', 'r'] corresponds to ouptut ['s']\n",
      "Input: tensor([18, 47, 56, 57]) corresponds to ouptut 58\n",
      "Input: ['F', 'i', 'r', 's'] corresponds to ouptut ['t']\n",
      "Input: tensor([18, 47, 56, 57, 58]) corresponds to ouptut 1\n",
      "Input: ['F', 'i', 'r', 's', 't'] corresponds to ouptut [' ']\n",
      "Input: tensor([18, 47, 56, 57, 58,  1]) corresponds to ouptut 15\n",
      "Input: ['F', 'i', 'r', 's', 't', ' '] corresponds to ouptut ['C']\n",
      "Input: tensor([18, 47, 56, 57, 58,  1, 15]) corresponds to ouptut 47\n",
      "Input: ['F', 'i', 'r', 's', 't', ' ', 'C'] corresponds to ouptut ['i']\n",
      "Input: tensor([18, 47, 56, 57, 58,  1, 15, 47]) corresponds to ouptut 58\n",
      "Input: ['F', 'i', 'r', 's', 't', ' ', 'C', 'i'] corresponds to ouptut ['t']\n"
     ]
    }
   ],
   "source": [
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'Input: {context} corresponds to ouptut {target}')\n",
    "    print(f'Input: {decode(context.tolist())} corresponds to ouptut {decode([target.tolist()])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e94ef67-cb29-4805-8ad8-62a5826f4072",
   "metadata": {},
   "source": [
    "We enable the transformer to see context for a sentence with a length of 1 to length of context size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "850a0955-2ffd-4a38-a7db-7a1ed5137ba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.598687Z",
     "iopub.status.busy": "2025-03-29T08:53:40.598687Z",
     "iopub.status.idle": "2025-03-29T08:53:40.603353Z",
     "shell.execute_reply": "2025-03-29T08:53:40.603353Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.598687Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4b56ee-30b3-4c69-b541-7b05646936db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.604368Z",
     "iopub.status.busy": "2025-03-29T08:53:40.604368Z",
     "iopub.status.idle": "2025-03-29T08:53:40.608039Z",
     "shell.execute_reply": "2025-03-29T08:53:40.608039Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.604368Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # -> sample indexes for random sequences\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]).to(device) # -> sample sequences with a fixed context length\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix]).to(device) # -> sample y outputs\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cac9848-7908-4be5-880a-1ad45a517b2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.608948Z",
     "iopub.status.busy": "2025-03-29T08:53:40.608948Z",
     "iopub.status.idle": "2025-03-29T08:53:40.668470Z",
     "shell.execute_reply": "2025-03-29T08:53:40.668470Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.608948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8]) torch.Size([4, 8])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "print(xb.shape, yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdaa6897-0828-42b1-89c1-a87167906189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.668470Z",
     "iopub.status.busy": "2025-03-29T08:53:40.668470Z",
     "iopub.status.idle": "2025-03-29T08:53:40.674254Z",
     "shell.execute_reply": "2025-03-29T08:53:40.673848Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.668470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n', 't', ' ', 't', 'h', 'a', 't', ' ']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(xb[2].to('cpu').tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64367700-fce6-4495-9c21-86149083c065",
   "metadata": {},
   "source": [
    "## Simple Bi-Gram Language model\n",
    "\n",
    "Bigram language model, that only works with the last prediction of the model (context is only the one preceding token)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d96a1eb-ae43-4958-85c6-e3100ad1cd6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.675490Z",
     "iopub.status.busy": "2025-03-29T08:53:40.675490Z",
     "iopub.status.idle": "2025-03-29T08:53:40.681107Z",
     "shell.execute_reply": "2025-03-29T08:53:40.680712Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.675490Z"
    }
   },
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "\n",
    "        # idx and targets are both (B, T) tensor of integers\n",
    "        logits = self.token_embedding_table(idx) # output (B, T, C)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None  \n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) #Tensor reshape\n",
    "            targets = targets.view(B*T) # or .view(-1)\n",
    "            # Loss expects logits in another shape, rather than (B, T, C) -> (B, C, T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "\n",
    "            logits, loss = self(idx) \n",
    "\n",
    "            # Use only the last timestep - The main thing is that it's a Bi-Gram model, that's looking for the last timestep\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "\n",
    "            # Apply softmax to use probabilities\n",
    "            probs = F.softmax(logits, dim = -1) # (B, C)\n",
    "            \n",
    "            # Sample from distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples = 1) # (B, 1)\n",
    "\n",
    "            # Append sampled index to te running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim = 1) # (B, T+1)\n",
    "        # Generate outputs as (B, T+max_new_tokens)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3a67cec-deb2-4882-a3f7-3827d821cdeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.682177Z",
     "iopub.status.busy": "2025-03-29T08:53:40.681107Z",
     "iopub.status.idle": "2025-03-29T08:53:40.754488Z",
     "shell.execute_reply": "2025-03-29T08:53:40.754488Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.682177Z"
    }
   },
   "outputs": [],
   "source": [
    "m = BigramLanguageModel(vocab_size).to(device)\n",
    "logits, loss = m(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69f043be-b352-4560-b10e-f44cbd89f720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.754488Z",
     "iopub.status.busy": "2025-03-29T08:53:40.754488Z",
     "iopub.status.idle": "2025-03-29T08:53:40.823169Z",
     "shell.execute_reply": "2025-03-29T08:53:40.823169Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.754488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 65])\n",
      "tensor(5.0364, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(logits.shape)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "937a52fa-d68c-4864-a663-dcaad1394f6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.824120Z",
     "iopub.status.busy": "2025-03-29T08:53:40.824120Z",
     "iopub.status.idle": "2025-03-29T08:53:40.891560Z",
     "shell.execute_reply": "2025-03-29T08:53:40.891560Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.824120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', 'y', 'q', '$', ';', 't', 'f', 'B', 'f', 'R', 'O', 'k', 'N', 'd', 'c', 'u', 'w', 'd', 'Z', 'Z', 'T', 'k', 'O', 'M', 'l', ';', ',', 'e', 'r', 't', 'K', '\\n', 'w', ':', '!', 'P', 'L', 'C', 'k', 'M', 'B', 'b', 'e', 'A', '$', '3', ':', 'X', 'a', 'S', 'G', 'J', 'O', '-', '3', 'p', '&', 'M', '-', 'c', '?', 'K', 'L', '3', 'a', 'u', 'h', 'p', 'F', 'Y', 'V', 'X', 'J', 'F', 'h', 'N', 'N', 'N', 'u', 'h', 'q', '$', 'O', 'M', 'x', 'v', '.', 't', 'b', 'V', 'F', 'Y', 'd', 'X', 'l', 'r', 'F', 'Z', 'a', 'A', 'e']\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device = device)\n",
    "print(decode(m.generate(context, max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f51787-02d9-4880-a244-168a2813d296",
   "metadata": {},
   "source": [
    "Train the model in order to increase it's efficiency and stability in text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92ccba10-365e-45d3-b31a-5b9f5d3fb99f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:40.891560Z",
     "iopub.status.busy": "2025-03-29T08:53:40.891560Z",
     "iopub.status.idle": "2025-03-29T08:53:42.057319Z",
     "shell.execute_reply": "2025-03-29T08:53:42.057319Z",
     "shell.execute_reply.started": "2025-03-29T08:53:40.891560Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cfff03f-1fe7-437e-9340-9baefea2982a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:42.057319Z",
     "iopub.status.busy": "2025-03-29T08:53:42.057319Z",
     "iopub.status.idle": "2025-03-29T08:53:55.058979Z",
     "shell.execute_reply": "2025-03-29T08:53:55.058979Z",
     "shell.execute_reply.started": "2025-03-29T08:53:42.057319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4487955570220947\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(10000):\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "995386c3-d438-4ad3-bea8-89e03dd833a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:53:55.060405Z",
     "iopub.status.busy": "2025-03-29T08:53:55.058979Z",
     "iopub.status.idle": "2025-03-29T08:53:55.229590Z",
     "shell.execute_reply": "2025-03-29T08:53:55.229590Z",
     "shell.execute_reply.started": "2025-03-29T08:53:55.060405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wawice my.\n",
      "\n",
      "HDEdarom oroup\n",
      "Yowhthetof isth ble mil; dill, ath iree sengmin lat Heriliovets, and Win nghir.\n",
      "Thanousel lind me l.\n",
      "HAshe ce hiry ptupr aisspllw y.\n",
      "Hurindu n Boopetelaves\n",
      "MPORDis, d mothakleo Windo whthCoribyo the m dourive we higend t so mower; te\n",
      "\n",
      "AN ad nterupt f s ar igr t m:\n",
      "\n",
      "Thiny aleronth,\n",
      "Mad\n",
      "RD:\n",
      "\n",
      "WISo myr f-NLIERor,\n",
      "Sb&hak\n",
      "Sadsal thes ghesthidin cour ay aney Iry ts I fr y ce.\n",
      "Jken pand, bemary.\n",
      "Yor 'Wour menm sora anghy t-senomes twe ten.\n",
      "Wand thot sulin s th llety ome.\n",
      "I muc\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device = device)\n",
    "print(''.join(decode(m.generate(context, max_new_tokens=500)[0].tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b5bb1a-0d86-48de-ac3d-177b6ab7c135",
   "metadata": {},
   "source": [
    "We've got a simple Bi-Gram model, that was looking only to last token from predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "351df774-4cc2-4edb-8e54-a0b7ed82141f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:09:14.145595Z",
     "iopub.status.busy": "2025-03-29T09:09:14.144307Z",
     "iopub.status.idle": "2025-03-29T09:09:14.152953Z",
     "shell.execute_reply": "2025-03-29T09:09:14.152566Z",
     "shell.execute_reply.started": "2025-03-29T09:09:14.145595Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model):\n",
    "    '''\n",
    "        Estimate loss outputs more stable loss metrics \n",
    "    due to averaging calculated loss by number of batches.\n",
    "    '''\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5b896-ea89-4a37-ae39-a5d61e34356c",
   "metadata": {},
   "source": [
    "## Sample self-attention blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a8f0d66-b8a2-4be6-b4e6-1b0753d8e212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:28:50.052778Z",
     "iopub.status.busy": "2025-03-29T09:28:50.051777Z",
     "iopub.status.idle": "2025-03-29T09:28:50.062743Z",
     "shell.execute_reply": "2025-03-29T09:28:50.062366Z",
     "shell.execute_reply.started": "2025-03-29T09:28:50.052778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4,8,2 # batch, timestemps, channels\n",
    "\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81356754-98a5-41ae-8837-fb3129aca7a5",
   "metadata": {},
   "source": [
    "Creating mechanism that will allow tokens to communicate with each other, by creating self-attention mechanism. This mechanism allows models to attend to earlier context, and omit further context of the message by using triangular matrices.\n",
    "\n",
    "This version of self-attention helps to communicate with earlier tokens by creating average or summed vectors of earlier context. Such process is quite lossy, but it's good enough for simple versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "22e8e94e-6ada-4d92-980f-5242057af430",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:46:10.098784Z",
     "iopub.status.busy": "2025-03-29T09:46:10.097880Z",
     "iopub.status.idle": "2025-03-29T09:46:10.105161Z",
     "shell.execute_reply": "2025-03-29T09:46:10.105161Z",
     "shell.execute_reply.started": "2025-03-29T09:46:10.098784Z"
    }
   },
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B, T, C))\n",
    "\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] #t, C\n",
    "        xbow[b, t] = torch.mean(xprev, 0) #averaging by time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5695dfdc-ac72-4598-99d3-b7ddd241a91c",
   "metadata": {},
   "source": [
    "This attention type is some averaging process, but very inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5c4988a-f033-48f7-bccc-88fdd4669f7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:46:11.204761Z",
     "iopub.status.busy": "2025-03-29T09:46:11.203762Z",
     "iopub.status.idle": "2025-03-29T09:46:11.213448Z",
     "shell.execute_reply": "2025-03-29T09:46:11.212487Z",
     "shell.execute_reply.started": "2025-03-29T09:46:11.204761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed8a2b2d-ae92-4034-8e85-89150d7b51d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:46:12.414433Z",
     "iopub.status.busy": "2025-03-29T09:46:12.412432Z",
     "iopub.status.idle": "2025-03-29T09:46:12.421184Z",
     "shell.execute_reply": "2025-03-29T09:46:12.421184Z",
     "shell.execute_reply.started": "2025-03-29T09:46:12.414433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e20b9aa-98f7-4a58-809e-5b3634830580",
   "metadata": {},
   "source": [
    "Matrix multiplication is the answer for creating a more faster version of an algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6bd96c13-1546-4f4a-bfe1-40327281b431",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:32:14.913330Z",
     "iopub.status.busy": "2025-03-29T09:32:14.912332Z",
     "iopub.status.idle": "2025-03-29T09:32:14.923507Z",
     "shell.execute_reply": "2025-03-29T09:32:14.923053Z",
     "shell.execute_reply.started": "2025-03-29T09:32:14.913330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "---\n",
      "b:\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c:\n",
      "tensor([[14., 16.],\n",
      "        [14., 16.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "\n",
    "c = a @ b\n",
    "\n",
    "print('a:', a, sep = '\\n')\n",
    "print('---')\n",
    "print('b:', b, sep = '\\n')\n",
    "print('---')\n",
    "print('c:', c, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "966fe6f0-efc6-4a00-9dd0-4677f8ae116f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:33:40.563157Z",
     "iopub.status.busy": "2025-03-29T09:33:40.562160Z",
     "iopub.status.idle": "2025-03-29T09:33:40.576514Z",
     "shell.execute_reply": "2025-03-29T09:33:40.576004Z",
     "shell.execute_reply.started": "2025-03-29T09:33:40.563157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da5e7a-6cfb-4ff8-9c9f-9daabb289d7f",
   "metadata": {},
   "source": [
    "By creating triangular matrix using `tril` we can omit further tokens and work with only preceding ones. Using masked filling we can also work with functions like `softmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4b041b8-a034-4311-8af5-350eb9f0a066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:35:59.153649Z",
     "iopub.status.busy": "2025-03-29T09:35:59.152640Z",
     "iopub.status.idle": "2025-03-29T09:35:59.164578Z",
     "shell.execute_reply": "2025-03-29T09:35:59.164578Z",
     "shell.execute_reply.started": "2025-03-29T09:35:59.153649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "---\n",
      "b:\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c:\n",
      "tensor([[ 2.,  7.],\n",
      "        [ 8., 11.],\n",
      "        [14., 16.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3)) \n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "\n",
    "c = a @ b\n",
    "\n",
    "print('a:', a, sep = '\\n')\n",
    "print('---')\n",
    "print('b:', b, sep = '\\n')\n",
    "print('---')\n",
    "print('c:', c, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e6b7a-5037-4a8b-89ca-bba1c35c7c81",
   "metadata": {},
   "source": [
    "In order to implement other functions like avearging or softmaxxing we can work with mutated triangular ones matrices.\n",
    "\n",
    "Averaging is done by the following process: lower traingular matrix is mutated to a weight matrix by normalizing it's ones to some weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6aedb1b4-2db0-4895-967d-a6d7a1ebf3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:39:58.444266Z",
     "iopub.status.busy": "2025-03-29T09:39:58.443543Z",
     "iopub.status.idle": "2025-03-29T09:39:58.456754Z",
     "shell.execute_reply": "2025-03-29T09:39:58.456352Z",
     "shell.execute_reply.started": "2025-03-29T09:39:58.444266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "---\n",
      "b:\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "---\n",
      "c:\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(3, 3)) \n",
    "a = a / torch.sum(a, 1, keepdim = True) # Normalize each row to create a weight matrix for further multiplications\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "\n",
    "c = a @ b\n",
    "\n",
    "print('a:', a, sep = '\\n')\n",
    "print('---')\n",
    "print('b:', b, sep = '\\n')\n",
    "print('---')\n",
    "print('c:', c, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ed1fabf7-f31d-42c8-9ce4-8540a4213920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:46:18.551617Z",
     "iopub.status.busy": "2025-03-29T09:46:18.550613Z",
     "iopub.status.idle": "2025-03-29T09:46:18.558984Z",
     "shell.execute_reply": "2025-03-29T09:46:18.558984Z",
     "shell.execute_reply.started": "2025-03-29T09:46:18.551617Z"
    }
   },
   "outputs": [],
   "source": [
    "xbow = torch.zeros((B, T, C))\n",
    "\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] #t, C\n",
    "        xbow[b, t] = torch.mean(xprev, 0) #averaging by time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988604e7-299e-4306-8a52-84a3674af128",
   "metadata": {},
   "source": [
    "This attention type is some averaging process, but very inefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d26a6c6c-a2b5-4384-aed1-30585e4a38d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:46:19.494211Z",
     "iopub.status.busy": "2025-03-29T09:46:19.490194Z",
     "iopub.status.idle": "2025-03-29T09:46:19.501646Z",
     "shell.execute_reply": "2025-03-29T09:46:19.500637Z",
     "shell.execute_reply.started": "2025-03-29T09:46:19.494211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.0894, -0.4926],\n",
       "        [ 0.1490, -0.3199],\n",
       "        [ 0.3504, -0.2238],\n",
       "        [ 0.3525,  0.0545],\n",
       "        [ 0.0688, -0.0396],\n",
       "        [ 0.0927, -0.0682],\n",
       "        [-0.0341,  0.1332]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d233d9f9-5885-4195-9937-8d398a5c0891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:46:20.015637Z",
     "iopub.status.busy": "2025-03-29T09:46:20.015637Z",
     "iopub.status.idle": "2025-03-29T09:46:20.025315Z",
     "shell.execute_reply": "2025-03-29T09:46:20.024307Z",
     "shell.execute_reply.started": "2025-03-29T09:46:20.015637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1808, -0.0700],\n",
       "        [-0.3596, -0.9152],\n",
       "        [ 0.6258,  0.0255],\n",
       "        [ 0.9545,  0.0643],\n",
       "        [ 0.3612,  1.1679],\n",
       "        [-1.3499, -0.5102],\n",
       "        [ 0.2360, -0.2398],\n",
       "        [-0.9211,  1.5433]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "542603bc-fa3f-4ac8-85be-332e658afe68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:46:21.905697Z",
     "iopub.status.busy": "2025-03-29T09:46:21.904699Z",
     "iopub.status.idle": "2025-03-29T09:46:21.913309Z",
     "shell.execute_reply": "2025-03-29T09:46:21.912078Z",
     "shell.execute_reply.started": "2025-03-29T09:46:21.905697Z"
    }
   },
   "outputs": [],
   "source": [
    "# Recreating averaging using matrices\n",
    "\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim = True)\n",
    "\n",
    "xbow2 = wei @ x # (T, T) @ (B, T, C) -> (B, T, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e01c6d-8cb1-45db-8ee1-e6c297903c97",
   "metadata": {},
   "source": [
    "wei shape is (T, T) @ and x shape is (B, T, C) which are inconsistent with each other. To conform with batch dimension torch will automatically create a batch dimension for wei tensor to perform batch multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82d70bd6-542b-4ab0-9ee0-99e7fde2856c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:46:22.565038Z",
     "iopub.status.busy": "2025-03-29T09:46:22.565038Z",
     "iopub.status.idle": "2025-03-29T09:46:22.573179Z",
     "shell.execute_reply": "2025-03-29T09:46:22.572173Z",
     "shell.execute_reply.started": "2025-03-29T09:46:22.565038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f196e589-dd6a-4edb-a0b6-61904e0e3029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:46:49.392047Z",
     "iopub.status.busy": "2025-03-29T09:46:49.390043Z",
     "iopub.status.idle": "2025-03-29T09:46:49.400795Z",
     "shell.execute_reply": "2025-03-29T09:46:49.399777Z",
     "shell.execute_reply.started": "2025-03-29T09:46:49.392047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]),\n",
       " tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0], xbow2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6903b9ab-f9b3-4a67-a2d7-355d1db424ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:51:23.926163Z",
     "iopub.status.busy": "2025-03-29T09:51:23.925166Z",
     "iopub.status.idle": "2025-03-29T09:51:23.933393Z",
     "shell.execute_reply": "2025-03-29T09:51:23.932387Z",
     "shell.execute_reply.started": "2025-03-29T09:51:23.926163Z"
    }
   },
   "outputs": [],
   "source": [
    "# third version with softmax\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "\n",
    "# transform zero elements to negative infinity - to limit token's abilities to communicate with earlier tokens\n",
    "wei = wei.masked_fill(tril == 0, float('-inf')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d451ab9c-e6e2-46e4-89fa-afdefb35f78d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:51:24.182233Z",
     "iopub.status.busy": "2025-03-29T09:51:24.182233Z",
     "iopub.status.idle": "2025-03-29T09:51:24.190730Z",
     "shell.execute_reply": "2025-03-29T09:51:24.190730Z",
     "shell.execute_reply.started": "2025-03-29T09:51:24.182233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5a6f2c42-d75e-4537-a409-9fd8b633475f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:51:36.584211Z",
     "iopub.status.busy": "2025-03-29T09:51:36.583220Z",
     "iopub.status.idle": "2025-03-29T09:51:36.591791Z",
     "shell.execute_reply": "2025-03-29T09:51:36.590779Z",
     "shell.execute_reply.started": "2025-03-29T09:51:36.584211Z"
    }
   },
   "outputs": [],
   "source": [
    "wei = F.softmax(wei, dim = -1)\n",
    "\n",
    "xbow3 = wei @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bc23017e-61cc-49fe-995a-d4642c14a5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T09:49:42.265164Z",
     "iopub.status.busy": "2025-03-29T09:49:42.261314Z",
     "iopub.status.idle": "2025-03-29T09:49:42.273913Z",
     "shell.execute_reply": "2025-03-29T09:49:42.273913Z",
     "shell.execute_reply.started": "2025-03-29T09:49:42.261314Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]),\n",
       " tensor([[ 0.1808, -0.0700],\n",
       "         [-0.0894, -0.4926],\n",
       "         [ 0.1490, -0.3199],\n",
       "         [ 0.3504, -0.2238],\n",
       "         [ 0.3525,  0.0545],\n",
       "         [ 0.0688, -0.0396],\n",
       "         [ 0.0927, -0.0682],\n",
       "         [-0.0341,  0.1332]]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0], xbow3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33496675-bf12-4d06-9ed0-bdd8e47faf23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
