{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24bf8520-81c5-4fdd-8bf9-cafd00bd4c70",
   "metadata": {},
   "source": [
    "# Seq2Seq model\n",
    "\n",
    "NLP Seq2Seq model from PyTorch official tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00a3f0df-ca18-44a3-9f32-2f3128cc0f5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:11.541871Z",
     "iopub.status.busy": "2025-03-17T18:47:11.541871Z",
     "iopub.status.idle": "2025-03-17T18:47:16.813989Z",
     "shell.execute_reply": "2025-03-17T18:47:16.813989Z",
     "shell.execute_reply.started": "2025-03-17T18:47:11.541871Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import os\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a643cb0-d6e5-417c-ac45-bd6ca0161757",
   "metadata": {},
   "source": [
    "Download and use data for further training and evaluation. [Data](https://www.manythings.org/anki/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3140239-e732-46ac-8b2f-4bf221226da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:16.813989Z",
     "iopub.status.busy": "2025-03-17T18:47:16.813989Z",
     "iopub.status.idle": "2025-03-17T18:47:16.820537Z",
     "shell.execute_reply": "2025-03-17T18:47:16.820537Z",
     "shell.execute_reply.started": "2025-03-17T18:47:16.813989Z"
    }
   },
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"<PAD>\": 0, \"<SOS>\":1, \"<EOS>\":2}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\"}\n",
    "        self.n_words = 3\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36600255-dddc-4fad-955a-eb39cc730542",
   "metadata": {},
   "source": [
    "The files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f7de8d-1ab9-436d-bc82-5872a8052045",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:16.820537Z",
     "iopub.status.busy": "2025-03-17T18:47:16.820537Z",
     "iopub.status.idle": "2025-03-17T18:47:16.826775Z",
     "shell.execute_reply": "2025-03-17T18:47:16.826775Z",
     "shell.execute_reply.started": "2025-03-17T18:47:16.820537Z"
    }
   },
   "outputs": [],
   "source": [
    "def unicodeToAscii(s): # Operates badly with russian words\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    '''\n",
    "    Remove non-letter characters\n",
    "    '''\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a0de59-364f-48af-8546-a9b812879999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:16.826775Z",
     "iopub.status.busy": "2025-03-17T18:47:16.826775Z",
     "iopub.status.idle": "2025-03-17T18:47:16.831889Z",
     "shell.execute_reply": "2025-03-17T18:47:16.831889Z",
     "shell.execute_reply.started": "2025-03-17T18:47:16.826775Z"
    }
   },
   "outputs": [],
   "source": [
    "def readLangs(file, lang1, lang2, reverse = False):\n",
    "\n",
    "    lines = open(os.path.join('data', f'{file}.txt'), encoding = 'utf-8').\\\n",
    "            read().strip().split(\"\\n\")\n",
    "    pairs = []\n",
    "    for l in tqdm(lines):\n",
    "        pairs.append([normalizeString(s) for s in l.split('\\t')[:2]])\n",
    "\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "MAX_LENGTH = 15\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in tqdm(pairs) if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f008c210-6f06-4834-a759-44f7eb2f906e",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "- Read text file and split into lines, split lines into pairs\n",
    "- Normalize text, filter by length and content\n",
    "- Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a2de24-134d-41a6-8989-0084bb0acbd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:16.831889Z",
     "iopub.status.busy": "2025-03-17T18:47:16.831889Z",
     "iopub.status.idle": "2025-03-17T18:47:16.836381Z",
     "shell.execute_reply": "2025-03-17T18:47:16.836381Z",
     "shell.execute_reply.started": "2025-03-17T18:47:16.831889Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepareData(data, lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(data, lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in tqdm(pairs):\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f72e57a3-999f-46a6-a5ab-0263da50cf81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:16.837386Z",
     "iopub.status.busy": "2025-03-17T18:47:16.837386Z",
     "iopub.status.idle": "2025-03-17T18:47:19.060932Z",
     "shell.execute_reply": "2025-03-17T18:47:19.060932Z",
     "shell.execute_reply.started": "2025-03-17T18:47:16.837386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e392a7eb680d4c58893f1e7dcd18e583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 135842 sentence pairs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c427463426b04d169d991a55f5272c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/135842 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimmed to 131951 sentence pairs\n",
      "Counting words...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0136643ee31d4f1aa9aedae991a2757f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/131951 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counted words:\n",
      "english 12532\n",
      "french 20641\n",
      "['i think you should think about the future', 'je pense que tu devrais penser a l avenir']\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('eng-fra', 'english', 'french')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfec5682-a28b-4a23-986f-ae5edda64083",
   "metadata": {},
   "source": [
    "## Seq2Seq model\n",
    "\n",
    "### Encoder part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f593000-24b3-478e-91d7-6e97bc2fbd52",
   "metadata": {},
   "source": [
    "![im1](https://pytorch.org/tutorials/_images/encoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ece58c7-13fc-4267-93e1-3f6de6178d8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:19.060932Z",
     "iopub.status.busy": "2025-03-17T18:47:19.060932Z",
     "iopub.status.idle": "2025-03-17T18:47:19.069901Z",
     "shell.execute_reply": "2025-03-17T18:47:19.069901Z",
     "shell.execute_reply.started": "2025-03-17T18:47:19.060932Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(input_size, hidden_size, padding_idx=PAD_token)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding_layer(input))\n",
    "        output, hidden = self.gru(embedded)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c3348-977f-4553-b983-ba947be2d79e",
   "metadata": {},
   "source": [
    "### Decoder part\n",
    "\n",
    "![decoder](https://pytorch.org/tutorials/_images/decoder-network.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e9994-8ba1-4b3a-abf8-fea2d8baca48",
   "metadata": {},
   "source": [
    "Simplest encoder-decoder architecture uses encoder's last hidden state to initialize weights of the decoder part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe099d24-d910-428d-a870-02de2608549a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:19.069901Z",
     "iopub.status.busy": "2025-03-17T18:47:19.069901Z",
     "iopub.status.idle": "2025-03-17T18:47:19.076116Z",
     "shell.execute_reply": "2025-03-17T18:47:19.076116Z",
     "shell.execute_reply.started": "2025-03-17T18:47:19.069901Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD_token)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor = None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "\n",
    "        for i in range(1, MAX_LENGTH + 1):\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing -> create vector of desired embeddings forced as next inputs\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "        \n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        # decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n",
    "\n",
    "    def forward_step(self, input, hidden):\n",
    "        output = self.embedding(input)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868fff8b-334e-454d-8d8c-5beb57e6d279",
   "metadata": {},
   "source": [
    "### Training Seq2Seq\n",
    "\n",
    "To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence). While creating these vectors we will append the `EOS` token to both sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4227ae0f-1485-4039-a742-89b745774b4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:19.076116Z",
     "iopub.status.busy": "2025-03-17T18:47:19.076116Z",
     "iopub.status.idle": "2025-03-17T18:47:19.080038Z",
     "shell.execute_reply": "2025-03-17T18:47:19.080038Z",
     "shell.execute_reply.started": "2025-03-17T18:47:19.076116Z"
    }
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980d85c5-927c-4f9d-9423-cb11fc427b10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:19.081042Z",
     "iopub.status.busy": "2025-03-17T18:47:19.080038Z",
     "iopub.status.idle": "2025-03-17T18:47:19.085218Z",
     "shell.execute_reply": "2025-03-17T18:47:19.085218Z",
     "shell.execute_reply.started": "2025-03-17T18:47:19.081042Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size, input_lang, output_lang, pairs):\n",
    "    # input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "\n",
    "    n = len(pairs)\n",
    "    # Data padds automatically, due to known position of PAD token\n",
    "    input_ids = np.zeros((n, MAX_LENGTH + 1), dtype=np.int32) \n",
    "    target_ids = np.zeros((n, MAX_LENGTH + 1), dtype=np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = [input_lang.word2index['<SOS>']] + indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = [output_lang.word2index['<SOS>']] + indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return input_lang, output_lang, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1822f64a-9ef2-4cec-80fa-424110c5bf25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:19.085218Z",
     "iopub.status.busy": "2025-03-17T18:47:19.085218Z",
     "iopub.status.idle": "2025-03-17T18:47:19.090069Z",
     "shell.execute_reply": "2025-03-17T18:47:19.090069Z",
     "shell.execute_reply.started": "2025-03-17T18:47:19.085218Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7b94e0c-ea8e-4f84-9c84-913002325cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:19.090069Z",
     "iopub.status.busy": "2025-03-17T18:47:19.090069Z",
     "iopub.status.idle": "2025-03-17T18:47:19.365750Z",
     "shell.execute_reply": "2025-03-17T18:47:19.365750Z",
     "shell.execute_reply.started": "2025-03-17T18:47:19.090069Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3348cac2-08e3-4c0e-a434-192c2a65124d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:19.365750Z",
     "iopub.status.busy": "2025-03-17T18:47:19.365750Z",
     "iopub.status.idle": "2025-03-17T18:47:19.372089Z",
     "shell.execute_reply": "2025-03-17T18:47:19.372089Z",
     "shell.execute_reply.started": "2025-03-17T18:47:19.365750Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8af94886-7177-4504-a315-a1ae3b82a8ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:19.372089Z",
     "iopub.status.busy": "2025-03-17T18:47:19.372089Z",
     "iopub.status.idle": "2025-03-17T18:47:19.378910Z",
     "shell.execute_reply": "2025-03-17T18:47:19.378150Z",
     "shell.execute_reply.started": "2025-03-17T18:47:19.372089Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(output_lang.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d82cabc-39cd-48b1-9a39-15fb4450b959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:19.380066Z",
     "iopub.status.busy": "2025-03-17T18:47:19.380066Z",
     "iopub.status.idle": "2025-03-17T18:47:19.383661Z",
     "shell.execute_reply": "2025-03-17T18:47:19.383661Z",
     "shell.execute_reply.started": "2025-03-17T18:47:19.380066Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59f324a2-8fe2-4ef5-b248-27cc14aef4b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:51.316567Z",
     "iopub.status.busy": "2025-03-17T18:47:51.315567Z",
     "iopub.status.idle": "2025-03-17T18:47:51.749927Z",
     "shell.execute_reply": "2025-03-17T18:47:51.749927Z",
     "shell.execute_reply.started": "2025-03-17T18:47:51.316567Z"
    }
   },
   "outputs": [],
   "source": [
    "_, _, tensor_dataset = get_dataloader(32, input_lang, output_lang, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4a49e71-4a23-4751-8c5a-b5c876f376a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T18:47:52.323983Z",
     "iopub.status.busy": "2025-03-17T18:47:52.323983Z",
     "iopub.status.idle": "2025-03-17T18:47:52.458400Z",
     "shell.execute_reply": "2025-03-17T18:47:52.458400Z",
     "shell.execute_reply.started": "2025-03-17T18:47:52.323983Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (480) to match target batch_size (512).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n\u001b[32m      7\u001b[39m decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_every\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(train_dataloader, encoder, decoder, n_epochs, learning_rate, print_every, plot_every)\u001b[39m\n\u001b[32m     10\u001b[39m criterion = nn.CrossEntropyLoss()\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, n_epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     loss = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     print_loss_total += loss\n\u001b[32m     15\u001b[39m     plot_loss_total += loss\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[39m\n\u001b[32m     11\u001b[39m encoder_outputs, encoder_hidden = encoder(input_tensor)\n\u001b[32m     12\u001b[39m decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoder_outputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_outputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m loss.backward()\n\u001b[32m     20\u001b[39m encoder_optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Notebooks\\.venv_Torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Notebooks\\.venv_Torch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Notebooks\\.venv_Torch\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1295\u001b[39m, in \u001b[36mCrossEntropyLoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m   1294\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Notebooks\\.venv_Torch\\Lib\\site-packages\\torch\\nn\\functional.py:3494\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3492\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3493\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3494\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3495\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3498\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3501\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Expected input batch_size (480) to match target batch_size (512)."
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "# input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "\n",
    "train(tensor_dataset, encoder, decoder, 20, print_every=5, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85ac58-105b-478b-9f92-f7a57ce35f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
